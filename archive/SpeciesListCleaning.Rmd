---
title: "SpeciesListCleaning"
author: "Beth Davis"
date: "2022-11-03"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# November 2022
Load in abbagadabba
```{r}
library(devtools)
install_github("Maine-eDNA/abbagadabba")

library(abbagadabba)
```

Read in the GBIF simple file (the species list was attempted but had an error and they should have the same taxonomy results so ignoring that error for now)

```{r}
simple <- read.table('~/Research/GBIFNovSimple.csv', sep = '\t', fill = TRUE, header = TRUE)
#slist <- read.table('~/Research/GBIFNovSpeciesList.csv', sep = '\t', fill = TRUE, header = TRUE)
```

Check the columns to make sure column selection is right and select all unique values for the species only (originally this was all taxonomy ranks and this resulted in the GBIFTaxa.csv file)

```{r}
#head(simple)

# Check that I can pull out just the taxonomic ranks
#head(simple[, 10])

GBIFspecies <- unique(simple[, 10])
```

Save the extracted unique species names to a separate dataframe and .csv

```{r}
GBIFResults <- as.data.frame(GBIFspecies)
write.csv(GBIFspecies, '~/Research/GBIFSpecies.csv')
```

Read in the non-GBIF data

```{r}
source <- read.csv('~/Desktop/SpeciesListMetatest.csv', header = TRUE)
```

Check and make sure all the data read in correctly

```{r}
tail(source)
```

Pull the unique values out and save to a new .csv

```{r}
sourcetaxa <- unique(source[, 1])
write.csv(sourcetaxa, '~/Research/NonGBIFTaxa.csv')
```

Clean taxa files and combine

```{r}
# cource sourcetaxa to a dataframe
sourcedspecies <- as.data.frame(sourcetaxa)
```

```{r}
head(GBIFResults)
head(sourcedspecies)

colnames(GBIFResults) <- c('Species')
colnames(sourcedspecies) <- c('Species')

head(GBIFResults)
head(sourcedspecies)
```

```{r}
results <- rbind(GBIFResults, sourcedspecies)

uniqueresults <- unique(results)
```

```{r}
write.csv(uniqueresults, '~/Research/MaineSpeciesList.csv')
```


# Continue on 2/21/2023 with the following goals:

* Run the species list through the abbagadabba cleaning codes and add on the other taxonomic ranks
* remove case insensitive duplicates
* Create a 'species_binomial' column for use in Erin's code

```{r listload, include = FALSE}
speclist <- readLines('C:/Users/bydav/Desktop/RefLib/MaineSpeciesList_Clean.csv')

subsettest <- read.csv('C:/Users/bydav/Desktop/RefLib/MaineSpeciesList_Clean_Subset.csv')

```

```{r}
if (!require("rentrez")) {install.packages("rentrez"); require("rentrez")} # Query ENTREZ databases and download accessions
set_entrez_key("c832cec80a76de1a62694193df8eb51d6608")
```

Think this should work, but hold off on running it on the full list until the cleaning of duplicates is done
```{r cleannames, include = FALSE}
testvec <- c('Idiomyia sproati', 'Drosophil murphy', 'no body')

specvec <- as.vector(speclist)

for (i in specvec) {
  x3 <- getNCBITaxonomy(i)
  print(x3)
}
```

```{r capital_test, include = FALSE}
library(stringr)

MaineDeDupList <- str_to_sentence(specvec, locale = "en")

MaineDeDupList
```

Now recheck for unique only


```{r}
MaineUnique2 <- unique(MaineDeDupList)
MaineUnique2

colnames(MaineSpecList) <- 'species_binomial'

MaineSpecList <- as.data.frame(MaineSpecList)
MaineSpecListUnique <- write.csv(MaineSpecList, "C:/Users/bydav/Desktop/RefLib/MaineSpecListUnique.csv")
```

Now run taxonomy
```{r}
#MaineTaxa_Test <- data.frame(kingdom=NA, phylum=NA, class=NA, order=NA, suborder=NA, infraorder = NA, superfamily = NA, family = NA, subfamily = NA, tribe = NA, genus = NA, species = NA, species_binomial = NA, old_name = NA, ncbi_name = NA, uid = NA) 

MaineTaxa_Test1 = 0


for (row in 1:nrow(MaineSpecList)) {
    for (col in 1:ncol(MaineSpecList)) {
        print(paste('Row', row, 'col', col, 'value', MaineSpecList[row, col]))
    }
}


for (i in MaineSpecList) {
  taxa <- getNCBITaxonomy(i)
  print(taxa)
}



```

Had to make some edits (change colnames and remove first row) from the species list. Wiping the environment and starting over from here

```{r}
listfull <- read.csv('C:/Users/bydav/Desktop/RefLib/MaineSpecListUnique.csv')
listset <- read.csv('C:/Users/bydav/Desktop/RefLib/MaineSpeciesList_Clean_Subset.csv')

library(abbagadabba)
library(stringr)
```


```{r}
for (i in listfull) {
  taxa <- getNCBITaxonomy(i)
  print(i) #counter
  print(taxa)
}

taxatest <- as.data.frame(taxa)
```


# July 11, 2023
BYD

Goals:
Continue cleaning the species list (need to deal with capitalization inconsistencies (done), check for special characters (done), remove everything that isn't a 2 word species binomial (done), and remove duplicates again)

Write a little chunk to add new species to the list (and maybe record the row numbers so that downstream scripts and functions can also be run without having to rerun the entire document? Or should it be the other way around - run the to-be-added file first and then append?)


(using scan so it imports as a vector)
```{r import_full_list, echo = FALSE}
library(dplyr)
library(tidyr)
library(stringr)

encodetest <- scan("C:/Users/bydav/Desktop/MaineSpeciesList_Clean.csv", sep=',', what = "", quiet = TRUE, encoding = "latin1")
```
```{r cases, echo = FALSE}

# fix capitalization
encodes <- str_to_sentence(encodetest)
```

```{r binomial, echo = FALSE}

# I give up on doing regexp searches and replaces. Breaking the vector of names into a dataframe, separating by space so I can just join only the first two columns
encodetable <- as.data.frame(encodes) %>% separate(encodes, into = paste("column", 1:23, sep = " "))

# join the binomial back together
encodetable$source_binomial <- paste0(encodetable$`column 1`, sep=" ", encodetable$`column 2`)

# check for special characters and check results for any trues
pattern <- "/|:|\\?|<|>|\\|\\\\|\\*"

results <- grepl(pattern, encodetable$source_binomial)
```

I can't get (genus sp) or (genus cf) removed - keeping in for now, input requested

```{r genera, echo = FALSE}
# pick out just the genera 
generalist <- encodetable$`column 1`

# find only the unique genera
genera <- unique(generalist)
MaineGenera <- write.csv(genera, "C:/Users/bydav/Desktop/MaineGenera.csv")

```

```{r unique_export, echo = FALSE}
# remove uniques and export to a new file
encodeunique <- unique(encodetable$source_binomial)

cleanlist <- write.csv(encodeunique, "C:/Users/bydav/Desktop/CleanSpecies.csv")
```












